---
title: 'NLNP Praktikum 5'
author: 'Robin Baudisch, Merlin Kopfmann, Maximilian Neudert'
output:
  pdf_document:
    latex_engine: lualatex
    includes:
      in_header: 'style/preamble.tex'
      before_body: 'style/prefix.tex'
    fig_caption: true
    fig_width: 10
    fig_height: 5
    df_print: kable
    toc: false
fontsize: 11pt
geometry: 'margin=1in'
---

```{r global_options, echo=FALSE}
knitr::opts_chunk$set(
  cache = TRUE,
  comment = "",
  echo = TRUE,
  error = TRUE,
  out.width = "100%",
  tidy = TRUE,
  warning = FALSE,
  message = FALSE
)
```

```{r, echo=FALSE}
usepackage = function(package_name) 
{
  p = deparse(substitute(package_name))
  if (!is.element(p, installed.packages()[,1]))
    install.packages(p, dep = TRUE, repos = "http://cran.us.r-project.org")
  require(p, character.only = TRUE)
}

usepackage(formatR)
usepackage(ggplot2)
usepackage(tidyr)

set.seed(42)
```

<!---** Data Science **--->

```{r}
load('awards.RData')
load('DebTrivedi.RData')
```

# A1

## a)

```{r}
data = awards

# poisson regression
plm = glm(
  num_awards ~ prog + math,
  data = data,
  family= poisson
)
summary(plm)
```

Die Summary zeigt die Poisson-Regressionskoeffizienten für jede der Variablen sowie die Standardfehler, Z-Scores, p-Werte und $95\%$ Konfidenzintervalle für die Koeffizienten. 
Der Koeffizient für `math` liegt bei $0.07$. Die Variable `progAcademic` vergleicht zwischen `prog = "Academic"` und `prog = "General"` mit einem Koeffizienten von $1.08$. Die Variable `prog.Vocational` zeigt die erwartete Differenz in der Anzahl zwischen `prog = "Vocational"` und der Referenzgruppe `(prog = "General")` mit einem Koeffizienten von $0.37$.

## b)

```{r}
library(ggplot2)

pred = predict.glm(
  plm,
  type='response'
)

gg = ggplot(
  data = data,
  mapping = aes(
    x = math,
    y = num_awards,
    color = prog
  )
)
# gg = gg + geom_point()
gg = gg + geom_smooth(
  method = "glm",
  method.args = list(
    family = "poisson"
  ),
  se = FALSE
)
gg = gg + labs(
  x = "Math Score",
  y = "Erwartete Anzahl Awards"
)
gg

```

## c)

```{r fig.height=8}
par(mfrow=c(2,2))
plot(plm)
```

Da Academics eine signifikante statistische Auswirkung hat, findet man an den in den Residuenplots auch Muster eines Offsets wieder. In den Plots Residuals vs Fitted und Scale Location lässt sich die Zuordnung der Werte in die einzelnen Prog Gruppen erkennen. 

## d)

```{r}
lm = lm(
  num_awards ~ math + prog,
  data = data
)

pAIC <- AIC(plm)
lAIC <- AIC(lm)
```

\begin{center}
\begin{tabular}{ |c|c| }
  \hline
  Poisson AIC & Linear AIC\\
  $`r round(pAIC, 2)`$ & $`r round(lAIC, 2)`$\\ 
  \hline
\end{tabular}
\end{center}

Es zeigt sich ein niedrigerer AIC Wert bei der Poisson Regression als bei der linearen Regression. Ein niedriger AIC deutet auf ein besseres Modell hin als ein hoher AIC. Folglich ist die Poisson Regression als ein besseres Modell zu betrachten.

# A2

## a)

```{r}
load('DebTrivedi.RData')
plm = glm(
  ofp ~ health + numchron + hosp + married + medicaid,
  data = DebTrivedi,
  family = poisson
)
summary(plm)
```

Die Summary zeigt die Poisson-Regressionskoeffizienten für jede der Variablen sowie die Standardfehler, Z-Scores, p-Werte und $95\%$ Konfidenzintervalle für die Koeffizienten. 

\quote{poor health} und \quote{excellent health} sind jeweils neue Faktoren als Verhältnis zu \quote{average health}.

Es zeigt sich dass \quote{poor health} positiv mit Arztbesuchen korreliert ist und \quote{excellent health} negativ korreliert.
Zusätzlich weisen sowohl chronische Erkrankungen als als die Notwendigkeit eines Krankenhausaufenthalts eine positive Korrelation auf.

Die Parameter \quote{verheiratet} und \quote{staatliche Unterstützung} weisen keine signifikante statsitische Auswirkung auf.

## b)

```{r}
btx = plm$coefficients[1] + 2 * plm$coefficients[4] + plm$coefficients[6]
y = exp(btx)
y = round(y, 0)
```

Für die Poisson Regression gilt $\E(Y_i \vert x_i) = \exp(b^T x)$, also Berechnen wir $b^T x$ mit den Koeffizienten aus dem Modell und exponieren anschließend für den Erwartungswert.

Man kann $`r y`$ Arztbesuche erwarten.

## c)

```{r, echo = FALSE}
library('dplyr')
cBeob <- matrix(NA,nrow=3,ncol=2)
colnames(cBeob) <- c("hosp 0","hosp 1")
rownames(cBeob) <- c("poor","average","excellent")
cGesch <- matrix(NA,nrow=3,ncol=2)
colnames(cGesch) <- c("hosp 0","hosp 1")
rownames(cGesch) <- c("poor","average","excellent")

cBeob[2,1] <- sum(filter(DebTrivedi,health=='average'&hosp==0)$ofp)
cBeob[1,1] <- sum(filter(DebTrivedi,health=='poor'&hosp==0)$ofp)
cBeob[3,1] <- sum(filter(DebTrivedi,health=='excellent'&hosp==0)$ofp)
cBeob[2,2] <- sum(filter(DebTrivedi,health=='average'&hosp==1)$ofp)
cBeob[1,2] <- sum(filter(DebTrivedi,health=='poor'&hosp==1)$ofp)
cBeob[3,2] <- sum(filter(DebTrivedi,health=='excellent'&hosp==1)$ofp)
```

```{r, echo = FALSE}
data.frame(cBeob)
```

```{r, echo = FALSE}
glmCGesch <- glm(data = DebTrivedi, ofp~health+hosp, family="poisson")
cGesch[2,1] <- predict.glm(glmCGesch, data.frame(health='average',hosp=0),type='response')
nk21 <- dim(filter(DebTrivedi,health=='average'&hosp==0))[1]
cGesch[1,1] <- predict.glm(glmCGesch, data.frame(health='poor',hosp=0),type='response')
nk11 <- dim(filter(DebTrivedi,health=='poor'&hosp==0))[1]
cGesch[3,1] <- predict.glm(glmCGesch, data.frame(health='excellent',hosp=0),type='response')
nk31 <- dim(filter(DebTrivedi,health=='excellent'&hosp==0))[1]
cGesch[2,2] <- predict.glm(glmCGesch, data.frame(health='average',hosp=1),type='response')
nk22 <- dim(filter(DebTrivedi,health=='average'&hosp==1))[1]
cGesch[1,2] <- predict.glm(glmCGesch, data.frame(health='poor',hosp=1),type='response')
nk12 <- dim(filter(DebTrivedi,health=='poor'&hosp==1))[1]
cGesch[3,2] <- predict.glm(glmCGesch, data.frame(health='excellent',hosp=1),type='response')
nk32 <- dim(filter(DebTrivedi,health=='excellent'&hosp==1))[1]
```

```{r, echo = FALSE}
data.frame(cGesch)
```

```{r, echo = FALSE}
chisq <- ((cBeob[1,1]-nk11*cGesch[1,1])^2)/(nk11*cGesch[1,1])+
  ((cBeob[2,1]-nk21*cGesch[2,1])^2)/(nk21*cGesch[2,1])+
  ((cBeob[3,1]-nk31*cGesch[3,1])^2)/(nk31*cGesch[3,1])+
  ((cBeob[1,2]-nk12*cGesch[1,2])^2)/(nk12*cGesch[1,2])+
  ((cBeob[2,2]-nk22*cGesch[2,2])^2)/(nk22*cGesch[2,2])+
  ((cBeob[3,2]-nk32*cGesch[3,2])^2)/(nk32*cGesch[3,2])
```

```{r, echo = FALSE}
data.frame(chisq)
```


- $\H{0}{Erwartete und beobachtete Häufigkeiten sind gleichverteilt}$
- $\H{1}{Erwartete und beobachtete Häufigkeiten sind nicht gleichverteilt}$

Der errechnete Wert des Chi-Quadrat Anpassungstests liegt über $11.07$ und damit im Ablehnungsbereich. H$_0$ kann also verworfen und H1 angenommen werden.

## d)

```{r, fig.height=8}
par(mfrow=c(2,2))
plot(plm)
```